{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mining-software-repositories/treinamento/blob/main/test_cassandra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clona o repositório Cassandra\n",
    "!git clone https://github.com/apache/cassandra.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clona o repositorio msr_test para acessar as libs proprietárias\n",
    "!git clone https://github.com/giselesousar/msr_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostra todos os commits entre as tags 3.0.0 e 3.11.11\n",
    "!cd cassandra && git log --pretty=\"%H;%ai;%s\" cassandra-3.0.0...cassandra-3.11.11 > commits-3.0.0-3.11.11-full.txt\n",
    "!cd cassandra && git log --pretty=\"%H %s\" cassandra-3.0.0...cassandra-3.11.11 > commits-3.0.0-3.11.11.txt\n",
    "!echo \"10 primeiros commits entre as versões cassandra-3.0.0...cassandra-3.11.11\"\n",
    "!cd cassandra && head commits-3.0.0-3.11.11.txt\n",
    "!echo \"...\"\n",
    "\n",
    "# Total de commits registrados entre as versões cassandra-3.0.0...cassandra-3.11.11\n",
    "!echo \"Total de commits registrados entre as versões cassandra-3.0.0...cassandra-3.11.11: \"\n",
    "!cd cassandra && cat commits-3.0.0-3.11.11.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta Commits e arquivos\n",
    "# Lista os commits entre duas tags\n",
    "!cd cassandra && git log --pretty=\"%H\" cassandra-3.0.0...cassandra-3.11.11 > commmitstags300to31111.txt\n",
    "commits_tag_3_from_000_to_111111 = !cd cassandra && cat commmitstags300to31111.txt\n",
    "print(f'Qtd: { len(commits_tag_3_from_000_to_111111) }, {commits_tag_3_from_000_to_111111}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixa o arquivo sqlite do banco dos commmits do Cassandra\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1n2RE3xsLtD-fv_omcI6vtm6x5si-PxmZ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1n2RE3xsLtD-fv_omcI6vtm6x5si-PxmZ\" -O msrcassandra300to31111.db && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treinamento.utils.dao as dao\n",
    "import treinamento.utils.utility as utility\n",
    "import datetime\n",
    "from pydriller import Repository\n",
    "\n",
    "path_repository = 'cassandra'\n",
    "\n",
    "def load_db(path_repository, create=False):\n",
    "    ## 1. Carrega o banco de dados e cria as estruturas das tabelas\n",
    "    print(f'Configura e carrega o banco {dao.data_base}...')\n",
    "    db_session = dao.create_session()\n",
    "    print(f'Banco {dao.data_base} carregado com sucesso! \\n')\n",
    "\n",
    "    # 2. Carrega os manipuladores de CommitComplete e FileComplete\n",
    "    commitsCompleteCollection = dao.CommitsCompleteCollection(session=db_session)\n",
    "    filesCompleteCollection = dao.FilesCompleteCollection(session = db_session)\n",
    "\n",
    "    if create: \n",
    "        dao.drop_tables()\n",
    "        dao.create_tables()\n",
    "\n",
    "        # 3. É preciso percorrer todos os commits, seus arquivos modificados e salva-los no Banco\n",
    "        print('Percorrendo todos os commits da lista commits_tag_3_from_000_to_111111...')\n",
    "        t1 = datetime.datetime.now()\n",
    "        print(t1)\n",
    "\n",
    "        for commit in Repository(path_repository, only_commits=commits_tag_3_from_000_to_111111).traverse_commits():    \n",
    "            c = dao.CommitComplete(name = commit.hash, \n",
    "                hash = commit.hash, \n",
    "                msg = commit.msg,\n",
    "                author = utility.concat_str(commit.author.name,commit.author.email), \n",
    "                committer = utility.concat_str(commit.committer.name,commit.committer.email), \n",
    "                author_date = commit.author_date,\n",
    "                author_timezone = commit.author_timezone,\n",
    "                committer_date = commit.committer_date,\n",
    "                committer_timezone = commit.committer_timezone,\n",
    "                branches = utility.convert_list_to_str(commit.branches),\n",
    "                in_main_branch = commit.in_main_branch,\n",
    "                merge = commit.merge,\n",
    "                modified_files = utility.convert_modifield_list_to_str(commit.modified_files),\n",
    "                parents = utility.convert_list_to_str(commit.parents),\n",
    "                project_name = commit.project_name,\n",
    "                project_path = commit.project_path,\n",
    "                deletions = commit.deletions,\n",
    "                insertions = commit.insertions,\n",
    "                lines = commit.lines,\n",
    "                files = commit.files,\n",
    "                dmm_unit_size = commit.dmm_unit_size,\n",
    "                dmm_unit_complexity = commit.dmm_unit_complexity,\n",
    "                dmm_unit_interfacing = commit.dmm_unit_interfacing)\n",
    "            \n",
    "            commitsCompleteCollection.insert_commit(c)\n",
    "\n",
    "            for m in commit.modified_files:\n",
    "                commit_by_hash = commitsCompleteCollection.query_commit_by_hash(commit.hash)\n",
    "                if m is not None and  m.filename is not None:\n",
    "                    if '.java' in m.filename:\n",
    "                        is_java = True\n",
    "                    else:\n",
    "                        is_java = False\n",
    "                    mf = dao.FileComplete(\n",
    "                        name = m.filename,\n",
    "                        hash = commit.hash,\n",
    "                        is_java = is_java,\n",
    "                        old_path = m.old_path,\n",
    "                        new_path = m.new_path,\n",
    "                        filename = m.filename,\n",
    "                        change_type = m.change_type.name,\n",
    "                        diff = str(m.diff),\n",
    "                        diff_parsed = utility.convert_dictionary_to_str(m.diff_parsed),\n",
    "                        added_lines = m.added_lines,\n",
    "                        deleted_lines = m.deleted_lines,\n",
    "                        source_code = str(m.source_code),\n",
    "                        source_code_before = str(m.source_code_before),\n",
    "                        methods = utility.convert_list_to_str(m.methods),\n",
    "                        methods_before = utility.convert_list_to_str(m.methods_before),\n",
    "                        changed_methods = utility.convert_list_to_str(m.changed_methods),\n",
    "                        nloc = m.nloc,\n",
    "                        complexity = m.complexity,\n",
    "                        token_count = m.token_count, \n",
    "                        commit_id = commit_by_hash.id\n",
    "                    )\n",
    "                    # salva o arquivo correte\n",
    "                    filesCompleteCollection.insert_file(mf)\n",
    "\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(t2)\n",
    "        print(f'Analise concluida em: {t2 -t1}')\n",
    "\n",
    "    return filesCompleteCollection, commitsCompleteCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carrega o banco de dados\n",
    "# Obs: o parâmetro create deve ser setado para True caso deseje recriar o banco do zero.\n",
    "filesCompleteCollection, commitsCompleteCollection = load_db(path_repository, create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as tabelas do banco em dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "DATA_BASE='msrcassandra300to31111.db'\n",
    "con = sqlite3.connect(DATA_BASE)\n",
    "\n",
    "my_query_commits = \"select * from commitscomplete\"\n",
    "my_query_files = \"select * from filescomplete\"\n",
    "my_query_files_commits = \"select f.id as 'file_id', f.hash as 'file_hash_commit', f.description as 'file_description', f.is_java as 'file_is_java', f.created_date as 'file_created_date', f.old_path as 'file_old_path', f.new_path as 'file_new_path', f.filename as 'file_filename', f.change_type as 'file_change_type', f.diff as 'file_diff', f.diff_parsed as 'file_diff_parsed', f.added_lines as 'file_added_lines', f.deleted_lines as 'file_deleted_lines', f.source_code as 'file_source_code', f.source_code_before as 'file_source_code_before', f.nloc as 'file_nloc', f.complexity as 'file_complexity', f.token_count as 'file_token_count', f.commit_id as 'file_commit_id', c.* from filescomplete f, commitscomplete c where f.commit_id=c.id\"\n",
    "\n",
    "df_commits_from_db = pd.read_sql_query(my_query_commits, con)\n",
    "df_files_from_db = pd.read_sql_query(my_query_files, con)\n",
    "df_files_commits_from_db = pd.read_sql(my_query_files_commits, con)\n",
    "\n",
    "con.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz alguns ajustes nos dataframes\n",
    "df_files_from_db['modified_lines'] = df_files_from_db.added_lines + df_files_from_db.deleted_lines\n",
    "df_files_commits_from_db['modified_lines'] = df_files_commits_from_db.file_added_lines + df_files_commits_from_db.file_deleted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista os commits e seus arquivos modificados\n",
    "df_commits_from_db[['name', 'modified_files']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procura por um commit especifico\n",
    "df_commits_from_db[['name', 'modified_files']].query(\"name == '47341eb6aaca318d0ffc0e9f906b98db50b9e9ff'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os arquivos e seus commits\n",
    "df_files_from_db[['name', 'hash']].sort_values('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra as Complexidades Ciclomáticas dos arquivos\n",
    "df_files_commits_from_db[['file_filename', 'file_complexity', 'author_date']].sort_values(by=['file_filename', 'author_date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra as complexidades ciclomáticas de um determinado arquivo\n",
    "df_files_commits_from_db[['file_filename', 'file_complexity', 'author_date']].sort_values(by=['file_filename', 'author_date'], ascending=True).query(\"file_filename == 'StorageService.java'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula frequência dos arquivos na faixa de commits analisados\n",
    "list_of_files_frequency_in_commits = {}\n",
    "\n",
    "# Dataframe agrupados por arquivos e seus commits\n",
    "df_groupby_name = df_files_from_db[['name', 'hash']].groupby('name')\n",
    "\n",
    "print(f'Quantidade de grupos: {df_groupby_name.ngroups}')\n",
    "print(f'Grupos: {df_groupby_name.groups}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_files = df_groupby_name.size()\n",
    "print(group_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files_frequency_in_commits = group_files.to_dict()\n",
    "print(f'{ len(list_of_files_frequency_in_commits) }, {list_of_files_frequency_in_commits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files_from_db[['name','modified_lines']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_name_modified_lines = df_files_from_db[['name','modified_lines']].groupby('name')\n",
    "\n",
    "group_files_modified_lines = df_groupby_name_modified_lines.sum()\n",
    "\n",
    "list_of_files_modified_lines = group_files_modified_lines.to_dict()\n",
    "print(f'{ len(list_of_files_modified_lines) }, {list_of_files_modified_lines}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
